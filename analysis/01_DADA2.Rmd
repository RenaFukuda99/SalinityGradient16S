---
title: "Infer ASVs with DADA2"
output: html_document
  toc: yes
    toc_float: 
      collapsed: no
      smooth_scroll: yes
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      fig.align = "center", 
                      fig.path = "../figures/01_DADA2/")

```

```{r set_seed, include=FALSE}
# Set my seed - can choose any number
set.seed(23598)
```

# Goals of this file
1. Use raw fastq files and generate quality plots to assess quality of reads.
2. Filter and trim out bad seqs and bases from seq files.
3. Write out fastq files with high quality seqs. 
4. Evaluate quality from filter and trim. 
5. Infer errors on forward and reverse reads individually.
6. Identify ASVs on forward and reverse reads separately using the error model.
7. Merge the forward and reverse ASVs into "contiguous" ASVs. 
8. Generate ASV count table (otu_table input for phyloseq).  

# Output that we need
1. ASV count table: otu_table
2. Taxonomy table: tax_table
3. Sample information (track reads lost through DADA2 pipeline): sample_data

# Load libraries
```{r load_libraries}
#install.packages("devtools")
library(devtools)

#devtools::install_github("benjjneb/dada2")
library(dada2)

#install.packages("tidyverse")
library(tidyverse)

#install.packages("patchwork")
library(patchwork)
```

# Load data
```{r load_data}
# Set raw fastq path to the raw seq files
# PATH to fastq files

raw_fastq_path <- "data/01_DADA2/01_raw_gzip_fastqs"

# What files are in this path? 
head(raw_fastq_path)

# How many files are there?
str(list.files(raw_fastq_path))

# Create a vector of forwards reads
forward_reads <- list.files(raw_fastq_path, pattern = "R1_001.fastq.gz", full.names = TRUE)
head(forward_reads)

# Create a vector of reverse reads
reverse_reads <- list.files(raw_fastq_path, pattern = "R2_001.fastq.gz", full.names = TRUE)
head(reverse_reads)
```

# Raw quality plots
```{r raw_quality_plot}
# Randomly select two samples from dataset to evaluate
random_samples <- sample(c(1:length(reverse_reads)),2)

# Calculate and plot the quality of two samples
plotQualityProfile(forward_reads[random_samples]) +
  labs(title = "Forward Read Raw Quality")
plotQualityProfile(reverse_reads[random_samples]) +
  labs(title = "Reverse Read Raw Quality")
```

# Prepare placeholder for filtered reads
```{r prep_filtered_seqs}
# Make vector of our samples, extract sample name from files
samples <- sapply(strsplit(basename(forward_reads), "_"),`[`,1)
head(samples)

# Place filtered reads into filtered fastq paths
filt_fastq_path <- "/local/workdir/rf384/git_repos/SalinityGradient16S/data/01_DADA2/02_filtered_fastqs"

# Create 2 vars - one for forward, one for reverse
filt_forward_reads <- file.path(filt_fastq_path, paste0(samples, "_R1_filtered.fastq.gz"))
filt_reverse_reads <- file.path(filt_fastq_path, paste0(samples, "_R2_filtered.fastq.gz"))
```


# Filter and trim reads
Parameters of filter and trim depend on the dataset
- maxN: number of N bases. Default is $0$, removes all Ns from dataset.
- maxEE: quality filtering threshold applied to expected errrors. Default is $2$, allows up to $2$ expected errors. There are two values - the first value is for forward reads, the second for reverse.  
- trimLeft: Number of bases to remove from beginning of the read (here $3$). 
- trunQ: Truncate reads at the first instance of a quality score less than or equal to truncQ.

```{r filter_and_trim}
# Assign a vector to filtered reads
# Trim out poor bases and first 3 bps on F reads
# Write out fastq files
filtered_reads <- filterAndTrim(fwd = forward_reads, filt = filt_forward_reads, 
                     rev = reverse_reads, filt.rev = filt_reverse_reads,
                     maxEE = c(2,2), trimLeft = 3, truncQ = 2, rm.phix = TRUE,
                     compress = TRUE) #multithread = TRUE
```

## Trimmed quality plots
```{r filt_trim_quality_plot}
# Calculate and plot the quality of two filtered/trimmed samples
plotQualityProfile(filt_forward_reads[random_samples]) +
  labs(title = "Trimmed forward read quality")
plotQualityProfile(filt_reverse_reads[random_samples]) _
  labs(title = "Trimmed reverse read quality")
```

## Aggregated Trimmed Plots
```{r aggregate_all_qc_plots}
plotQualityProfile(filt_forward_reads, aggregate = TRUE)
plotQualityProfile(filt_reverse_reads, aggregate = TRUE)
```

## Stats on read output from filterAndTrim
```{r filterTrim_stats}
# Make into dataframe
filtered_df <- as.data.frame(filtered_reads)
head(filtered_df)

# Calculate some stats
filtered_df %>%
  reframe(median_reads_in = median(reads.in),
          median_reads_out = median(reads.out),
          median_perc_related = median(reads.in)/median(reads.out))
```

# Error modeling
Run separately on each Illumina dataset.
Trying to determine between biological variation and sequencing error - must rerun per sequencing run.
```{r learn_errors}
# Forward reads
error_forward_reads <- learnErrors(filt_forward_reads, multithread = 2) #or 5

# Reverse reads
error_reverse_reads <- learnErrors(filt_reverse_reads, multithread = 2) #multithread = 2 or 5

# Plot it
plotErrors(error_forward_reads, nominalQ = TRUE) + 
  labs(title = "Forward Read Error Model")
plotErrors(error_reverse_reads, nominalQ = TRUE) +
  labs(title = "Reverse Read Error Model")
```

# Infer ASVs
Happening independently on forward and reverse reads - this is unique to DADA2. 
```{r infer_ASVs}
# Infer forward ASVs
dada_forward <- dada(filt_forward_reads, error_forward_reads) #multithred = TRUE

# Infer reverse ASVs
dada_reverse <- dada(filt_reverse_reads, error_reverse_reads) #multithred = TRUE 
```

# Merge forward and reverse ASVs
```{r merge_ASVs}
# Merge forward and reverse ASVs
merged_ASVs <- mergePairs(dada_forward, filt_forward_reads, 
                         dada_reverse, filt_reverse_reads, 
                         verbose = TRUE)

# Evaluate output 
typeof(merged_ASVs)
length(merged_ASVs)
name(merged_ASVs)
```

# Generate ASV count table
```{r generate_ASV_table}
# Create ASV count table
raw_ASV_table <- makeSequenceTable(merged_ASVs)

# Write out the file to data/01_DADA2
```


# Session information
```{r session_info}
# Ensure reproducibility
devtools::session_info()
```

